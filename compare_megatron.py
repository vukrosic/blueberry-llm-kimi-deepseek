#!/usr/bin/env python3
"""
Compare Megatron vs Native PyTorch training performance.
"""

import subprocess
import sys
import time
import os

def run_training(backend_name, megatron_flag, max_steps=50):
    """Run training with specified backend."""
    print(f"\n{'='*60}")
    print(f"ğŸš€ Testing {backend_name}")
    print(f"{'='*60}")
    
    cmd = [
        sys.executable, "train.py",
        megatron_flag,
        "--max-steps", str(max_steps),
        "--batch-size", "8",  # Smaller batch for faster testing
        "--num-documents", "500"  # Smaller dataset for faster testing
    ]
    
    print(f"Command: {' '.join(cmd)}")
    print()
    
    start_time = time.time()
    try:
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
        end_time = time.time()
        
        print(f"â±ï¸ Training time: {end_time - start_time:.1f} seconds")
        print(f"ğŸ“Š Exit code: {result.returncode}")
        
        # Extract key metrics from output
        lines = result.stdout.split('\n')
        for line in lines:
            if 'it/s' in line or 'loss=' in line or 'Training:' in line:
                print(f"ğŸ“ˆ {line.strip()}")
        
        return {
            'backend': backend_name,
            'time': end_time - start_time,
            'success': result.returncode == 0,
            'output': result.stdout
        }
        
    except subprocess.TimeoutExpired:
        print("â° Training timed out after 5 minutes")
        return {
            'backend': backend_name,
            'time': 300,
            'success': False,
            'output': "Timeout"
        }
    except Exception as e:
        print(f"âŒ Error: {e}")
        return {
            'backend': backend_name,
            'time': 0,
            'success': False,
            'output': str(e)
        }

def main():
    print("ğŸ« Blueberry LLM: Megatron vs Native Comparison")
    print("=" * 60)
    
    # Test configurations
    configs = [
        ("Native PyTorch", "--no-megatron"),
        ("Megatron-LM", "--use-megatron")
    ]
    
    results = []
    
    for backend_name, flag in configs:
        result = run_training(backend_name, flag)
        results.append(result)
    
    # Print comparison summary
    print(f"\n{'='*60}")
    print("ğŸ“Š COMPARISON SUMMARY")
    print(f"{'='*60}")
    
    for result in results:
        status = "âœ… SUCCESS" if result['success'] else "âŒ FAILED"
        print(f"{result['backend']:20} | {result['time']:6.1f}s | {status}")
    
    # Performance comparison
    if len(results) == 2 and all(r['success'] for r in results):
        native_time = results[0]['time']
        megatron_time = results[1]['time']
        
        if megatron_time < native_time:
            speedup = native_time / megatron_time
            print(f"\nğŸš€ Megatron is {speedup:.1f}x faster!")
        else:
            slowdown = megatron_time / native_time
            print(f"\nğŸŒ Megatron is {slowdown:.1f}x slower")
    
    print(f"\n{'='*60}")
    print("ğŸ’¡ Tips:")
    print("   - Check GPU utilization: nvidia-smi")
    print("   - Monitor memory usage during training")
    print("   - Look for 'Data Parallel' vs 'Megatron' in output")
    print("   - Compare training speed (it/s)")

if __name__ == "__main__":
    main()
